{"cells":[{"cell_type":"markdown","metadata":{"id":"TqWVF4SF0pn2"},"source":["# Exercise 3\n","\n","## Instructions:\n","\n","- All previous instructions hold.\n","- In addition, if you are using GPU, you must check that your code also runs on a CPU.\n","- **Make sure you use the best practices you learned in class**."]},{"cell_type":"markdown","source":["## Intro:\n","\n","So far we had to manually implement both the forward and backward passes of our neural network. Manually implementing the backward pass is not a big deal for a small two-layer network, but can quickly get very messy for large complex networks.\n","\n","Thankfully, We learned in the reciation that we can use **automatic differentiation** to automate the computation of backward passes in neural networks. The autograd package in PyTorch provides exactly this functionality. When using autograd, the forward pass of your network will define a computational graph. Nodes in the graph will be Tensors,\n","and edges will be functions that produce output Tensors from input Tensors. Backpropagating through this graph then allows you to easily compute gradients.\n","\n","If we want to compute gradients with respect to some Tensor, then we set `requires_grad=True` when constructing that Tensor. Any PyTorch operations on that Tensor will cause a computational graph to be constructed, allowing us to later perform backpropagation through the graph. If `x` is a Tensor with `requires_grad=True`, then after backpropagation `x.grad` will be another Tensor holding the gradient of `x`.\n","\n","Sometimes you may wish to prevent PyTorch from building computational graphs when performing certain operations on Tensors with `requires_grad=True`; for example, we usually don't want to backpropagate through the weight update steps when evaluating a neural network. In such scenarios we can use the `torch.no_grad()` context manager to prevent the construction of a computational graph.\n","\n","## In this exercise, you will accomplish the following:\n","1. Train a convolutional network using PyTorch.\n","2. Evaluate your model using a confusion matrix.\n","3. Solve the localization task using regression."],"metadata":{"id":"MHAMWkXMf4HI"}},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from google.colab import drive\n","import sys\n","import os"],"metadata":{"id":"c-ej_Ez_f3lR"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xH0l6STs0pn3"},"outputs":[],"source":["%matplotlib inline\n","plt.rcParams['figure.figsize'] = (12.0, 8.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'"]},{"cell_type":"markdown","metadata":{"id":"mrHi-X-M0pn4"},"source":["# Part A (40 points)\n","# Convolutional Neural Network - Classifiying CIFAR-10\n"]},{"cell_type":"markdown","metadata":{"id":"Fw6akpZY0pn4"},"source":["### Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M01YAOI30pn4","scrolled":true},"outputs":[],"source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MhT2YJ8g0pn5"},"outputs":[],"source":["# functions to show an image\n","def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0))) # plt accepts images in the format (w,h,c)\n","\n","# get some random training images\n","dataiter = iter(trainloader)\n","images, labels = next(dataiter)\n","\n","print(\"Image shape: \", images[0].shape)\n","# show images\n","imshow(torchvision.utils.make_grid(images[:4]))\n","# print labels\n","print(' '.join('%10s' % classes[labels[j]] for j in range(4)))"]},{"cell_type":"markdown","metadata":{"id":"MYizL6gI0pn5"},"source":["### Construct a CNN in PyTorch\n","\n","In the following class, initiate your different layers in the `__init__` method and define your architecture in the `forward` method. Make sure the `forward` method has a single return value.\n","\n","1. Make good use of the documentation and experiment will different layers, activations and architectures, batch sizes, regularization, filter sizes, dimensions, number of layers and whatever you learned in class.\n","2. Use your intuition from the previous exercises and additional sources such as the stackoverflow, Medium, etc. - **do not try to perform a massive grid search.**\n","3. **Include only your chosen architecture**. During experimentation, you may add as many cells as you need. Make sure to delete them before submission.\n","4. It is **NOT** allowed to use famous models that have been already implemented by PyTorch (resnet, densenet, alexnet, etc).\n","5. Make sure your code runs reasonably fast (no more than 15 minutes on CPU).\n","6. Use the best architecture you find and train it for 1-10 epochs.\n","7. Visualize the loss and accuracy of your network during training. You can use matplotlib.\n","8. You should get above 60% accuracy on the test set.\n","**(20 points)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tfeyA7BG0pn5","executionInfo":{"status":"error","timestamp":1765663943911,"user_tz":-120,"elapsed":4,"user":{"displayName":"Ofri Hefetz","userId":"05994547484574248582"}},"colab":{"base_uri":"https://localhost:8080/","height":106},"outputId":"0dd5854c-c98e-4462-b1f6-30fbd76e013e"},"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"expected an indented block after function definition on line 20 (ipython-input-3919900658.py, line 36)","traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3919900658.py\"\u001b[0;36m, line \u001b[0;32m36\u001b[0m\n\u001b[0;31m    net = Net().to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\u001b[0m\n\u001b[0m                                                                                ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 20\n"]}],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        #############################################################################\n","        # TO DO:                                                                    #\n","        # Initiate the different layers you wish to use in your network.            #\n","        # This method has no return value.                                          #\n","        #############################################################################\n","\n","\n","\n","\n","\n","\n","\n","        #############################################################################\n","        #                             END OF YOUR CODE                              #\n","        #############################################################################\n","\n","    def forward(self, x):\n","        #############################################################################\n","        # TO DO:                                                                    #\n","        # Define the forward propagation. You need to pass an image through the     #\n","        # network and obtain class predictions.                                     #\n","        # This function returns the predication of your model.                      #\n","        #############################################################################\n","\n","\n","\n","\n","\n","        #############################################################################\n","        #                             END OF YOUR CODE                              #\n","        #############################################################################\n","\n","net = Net().to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n","criterion = None\n","optimizer = None\n","#############################################################################\n","# TO DO:                                                                    #\n","# Define the loss function and optimizer.                                   #\n","#############################################################################\n","\n","\n","\n","#############################################################################\n","#                             END OF YOUR CODE                              #\n","#############################################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PV_oCNmw8N4W"},"outputs":[],"source":["#############################################################################\n","# TO DO:                                                                    #\n","# Define the training loop as seen in class and as demonstrated in the       #\n","# documentation. Note, if you are using GPU, make sure your code runs on    #\n","# CPU also. Code that cannot run will not be tested.                        #\n","#############################################################################\n","def train_model(model, train_loader, num_epochs):\n","\n","    train_losses = []\n","    train_accuracies = []\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","    return train_losses, train_accuracies\n","\n","\n","# -----------------------------------------------------------------------   #\n","# ---------------------------train & plots-------------------------------   #\n","# -----------------------------------------------------------------------   #\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","#############################################################################\n","#                             END OF YOUR CODE                              #\n","#############################################################################\n"]},{"cell_type":"markdown","metadata":{"id":"eIo0sCkl0pn5"},"source":["## Model evaluation\n","\n","Calculate the model accuracy on the test set and print a confusion matrix where the Y-axis represents the real category and the X-axis represents the predicted category. (10 points)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Rx4bvV00pn5"},"outputs":[],"source":["confusion_matrix = np.zeros([10,10], int)\n","model_accuracy = 0.0\n","#############################################################################\n","# TO DO:                                                                    #\n","# Define the evaluation loop as demonstrated in the                          #\n","# documentation and use the confusion matrix to evaluate your model.        #\n","#############################################################################\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","#############################################################################\n","#                             END OF YOUR CODE                              #\n","#############################################################################\n","print('Model accuracy on {0} test images: {1:.2f}%'.format(len(testset), model_accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JRIrr-AC0pn5"},"outputs":[],"source":["fig, ax = plt.subplots(1,1,figsize=(8,6))\n","ax.matshow(confusion_matrix, aspect='auto', vmin=0, vmax=1000, cmap=plt.get_cmap('RdPu'))\n","plt.ylabel('Actual Category')\n","plt.yticks(range(10), classes)\n","plt.xlabel('Predicted Category')\n","plt.xticks(range(10), classes)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"nTa3GfQM0pn6"},"source":["##**Question 1:**\n","Describe your experiments.\n","- Which specific hyperparameters (e.g., LR, Batch Size) or architectural changes (e.g., number of layers, kernel sizes) did you tweak?\n","- Did you encounter overfitting or underfitting? How did you solve it?\n","- Successes vs. Failures: Describe one configuration that failed or performed poorly, and try to explain why. Then, contrast it with what worked.\n","- What was the single most impactful change you made that boosted your accuracy over the 60% threshold?\n","   **(5 Points)**\n","\n","**Your answer:**\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Lq7U6Qp30pn6"},"source":["##**Question 2:**\n","What can you learn from the confusion matrix? Why do you need additional evaluation methods other than accuracy? **(5 Points)**\n","\n","**Your answer:**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"bSCChiEG0pn6"},"source":["# Part B (60 points)\n","# Localization as Regression\n","\n","In this next part, we will utilize a well-known architecture called ResNet18. This model has been pretrained on ImageNet, a dataset significantly larger and richer than CIFAR10, containing over 1 million images across 1,000 classes.\n","\n","The Goal: We will use the features extracted by the pretrained ResNet18 to perform a dual task: classifying and localizing images of ðŸˆ and ðŸ•.\n","\n","Why do this?\n","\n","Using a pretrained network as a building block for new tasksâ€”a technique known as Transfer Learningâ€”is a cornerstone of modern Deep Learning. By leveraging the robust visual features ResNet18 has already learned (like edges, textures, and shapes), we can train a high-performing model for our specific task using a surprisingly small number of images."]},{"cell_type":"markdown","source":["## âš ï¸ Prerequisite: Data Setup\n","Before starting Part 2, you must upload the provided data folder to your Google Drive.\n","\n","1. Download the data_hw3 folder provided with this assignment.\n","\n","2. Upload the entire data_hw3 folder to the root directory of your Google Drive (inside \"My Drive\").\n","\n","3. Mount Drive: Ensure your Drive is mounted in the notebook (run the cell below).\n","\n","Note: If you upload the folder inside other sub-folders, you will need to adjust the file paths in the code accordingly."],"metadata":{"id":"6RxG9jtam6Iz"}},{"cell_type":"code","source":["# 1. Mount the entire Drive to the standard location\n","drive.mount('/content/drive')\n","\n","# 2. Path to the folder you mounted\n","project_path = '/content/drive/MyDrive/data_hw3' # change if needed\n","\n","# Add it to the system path if it's not there\n","if project_path not in sys.path:\n","    sys.path.append(project_path)\n","\n","# Verify what is inside the folder (needs to be ['dataloader.py', 'animals'])\n","print(f\"Files found in {project_path}:\")\n","try:\n","    print(os.listdir(project_path))\n","except FileNotFoundError:\n","    print(\"Error: The path does not exist. Check if the folder name is exactly 'data_hw3'\")"],"metadata":{"id":"jkadf96kd7kE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oLp8-Ktx0pn6"},"outputs":[],"source":["from dataloader import bb_intersection_over_union as calculate_iou\n","from dataloader import *\n","from torchvision.models import resnet18, ResNet18_Weights\n","import matplotlib.patches as patches\n","import torchvision.models as models\n","from PIL import Image\n","import collections\n","import time\n","import copy\n"]},{"cell_type":"markdown","metadata":{"id":"sicH4JDM0pn6"},"source":["## load ResNet18\n","To load ResNet18 with the pretrained weights, use the following line. You are welcome to try different architectures, however they might require different input sizes or normalization.\n","\n","The first time you run this cell the weights will be downloaded."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"inqMCC8j0pn6"},"outputs":[],"source":["resnet18 = resnet18(weights=ResNet18_Weights.DEFAULT)"]},{"cell_type":"markdown","metadata":{"id":"dh91xy8R0pn6"},"source":["## Note:\n","ResNet takes as input images of size (224,224). We will use PyTorch Transforms to change the size of the images. When ResNet18 was trained on ImageNet, the images were normalized using the mean and standard deviation of the images. In order to properly use the weights, we will use the same normalization."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MjdlZRJR0pn6"},"outputs":[],"source":["data_transforms = {\n","    'train': transforms.Compose([\n","        Rescale((224,224)),\n","        ToTensor(),\n","        Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalizing according to imagenet\n","    ]),\n","    'val': transforms.Compose([\n","        Rescale((224,224)),\n","        ToTensor(),\n","        Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","root_dir = os.path.join(project_path,\"animals\")\n","datasets = {x: VOCDetection(root_dir, image_set=x, transform=data_transforms[x])\n","                  for x in ['train', 'val']}\n","dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=32, shuffle=True, num_workers=4)\n","              for x in ['train', 'val']}\n","dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val']}\n","classes = datasets['train'].classes\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","print(dataset_sizes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iBvBUT-A0pn6"},"outputs":[],"source":["# Get a batch of training data\n","sample = next(iter(dataloaders['train']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dYxQ3yaF0pn7"},"outputs":[],"source":["def imshow(img, label, bbox):\n","    image = np.copy(img[0])\n","    image = np.transpose(image, (1, 2, 0))\n","    image *= np.array([0.229, 0.224, 0.225])\n","    image += np.array([0.485, 0.456, 0.406])\n","    label = label[0]\n","    bbox = bbox[0]\n","    plt.figure();\n","    fig, ax = plt.subplots(1, figsize=(12,9));\n","    ax.imshow(image);\n","    x1, y1, x2, y2 = bbox.numpy().reshape(-1) * 224\n","    box_w, box_h = np.abs(x2-x1), np.abs(y2-y1)\n","    bbox = patches.Rectangle((x1, y1), box_w, box_h, linewidth=2,\n","                             edgecolor='r', facecolor='none');\n","    ax.add_patch(bbox);\n","    ax.annotate(classes[label], (x1, y1), color='r', fontsize=14);\n","\n","imshow(sample['image'],sample['label'],sample['bbox'])"]},{"cell_type":"markdown","source":["**(20 Points)**"],"metadata":{"id":"uAkslzaOq1AD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"C_wICkHh0pn7"},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(self, num_classes):\n","        super(CNN, self).__init__()\n","        #############################################################################\n","        # TO DO:                                                                    #\n","        # 1. Load the pretrained ResNet-18 network.                                 #\n","        # 2. Remove the top fully connected layer so we could use the features of   #\n","        #    the network and not the only the classification layer which carries     #\n","        #    significantly less information.                                         #\n","        #                                                                           #\n","        # 3. Heads: Define two separate sub-networks (heads) that take the           #\n","        #    backbone's output features as input:                                   #\n","        #      a) Classification Head: features -> FC layers -> class scores         #\n","        #      b) Detection Head:      features -> FC layers -> bbox coordinates    #\n","        #                                                                           #\n","        # Clarification:                                                             #\n","        # - You are effectively building a multi-task network with a shared         #\n","        #   backbone and two parallel output branches.                              #\n","        # - You may choose to freeze the backbone weights or train them.            #\n","        # - This function has no return value                                       #\n","        #############################################################################\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","        #############################################################################\n","        #                             END OF YOUR CODE                              #\n","        #############################################################################\n","\n","    def forward(self, images):\n","        #############################################################################\n","        # TO DO:                                                                    #\n","        # Define the forward propagation. You need to pass an image through the      #\n","        # network and extract the feature vector. In this case, when using a        #\n","        # predefined network, you don't want to change it's weights.                 #\n","        # The rest of the layers you defined should accepts gradients for them to    #\n","        # improve during training.                                                  #\n","        # This function returns a class predication and a bounding box coordinates. #\n","        #############################################################################\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","        #############################################################################\n","        #                             END OF YOUR CODE                              #\n","        #############################################################################"]},{"cell_type":"markdown","metadata":{"id":"2HSBASZM0pn7"},"source":["## Guidelines\n","\n","1. Complete the `train_model` function in the cell below. This function takes as input the model and additional hyper-parameters, and outputs the best model found on the validation set.\n","2. To babysit the learning process, **you must track the classification accuracy, IoU score and loss on the training and validation datasets and visualize them** (using matplotlib or similar). I have included an implementation of the IoU metric in the file `data_hw3\\dataloader.py`.\n","3. Do not perform a massive grid search!!\n","4. Use papers, blogs, MOOCs and online guides to research best hyper-parameters for your model.\n","5. You are encouraged to try Google Colab. If you have an CUDA capable GPU at home - you are welcome to use it.\n","5. **Include only your chosen architecture**. During experimentation, you may add as many cells as you need. Make sure to delete them before submission.\n","6. Training large neural networks may take a while. Make sure your code runs reasonably fast (~15 minutes on CPU and ~5 minutes on GPU).\n","7. Try to reach at least 90% classification accuracy and a IOU score of at least 0.60 on the validation set.\n","8. **In order to get full marks for this section explain the results and include visualizations.**.\n","9. You are given a general skeleton for the training function. Feel free to use any different structure.\n","\n","**(30 Points)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gTx01ImQ0pn7"},"outputs":[],"source":["def train_model(model, criterion_cls, criterion_bbox, optimizer, scheduler=None, num_epochs=5):\n","    since = time.time()\n","    best_model_wts = copy.deepcopy(model.state_dict()) # this is how a model is copied\n","    best_acc = 0.0\n","\n","    # added - track metrics\n","    history = {\n","        'train_loss': [], 'val_loss': [],\n","        'train_acc': [], 'val_acc': [],\n","        'train_iou': [], 'val_iou': []\n","    }\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0   # total loss of the network at each epoch\n","            running_corrects = 0 # number of correct predictions\n","            iou = 0.0            # IoU score\n","\n","            # Iterate over data.\n","            for sample in dataloaders[phase]:\n","                #############################################################################\n","                # TO DO:                                                                    #\n","                # Extract the data from the dataloader, calculate the predictions of your   #\n","                # network and calculate the loss of the classification and bounding box     #\n","                # prediction. When in training mode, back-prop and update the weights.      #\n","                # At each epoch, calculate the test and train accuracy and IoU.             #\n","                # This function returns the best model in terms of accuracy.                #\n","                #############################################################################\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","                #############################################################################\n","                #                             END OF YOUR CODE                              #\n","                #############################################################################\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = torch.tensor(running_corrects, dtype=torch.float32) / dataset_sizes[phase]\n","            iou = iou / dataset_sizes[phase]\n","\n","            # added - log metrics\n","            history[f'{phase}_loss'].append(epoch_loss)\n","            history[f'{phase}_acc'].append(epoch_acc.item())\n","            history[f'{phase}_iou'].append(iou)\n","\n","\n","            print('{} Loss: {:.4f}  |  Acc: {:.4f}  |  IOU: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc, iou))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model, history"]},{"cell_type":"markdown","metadata":{"id":"I07q4zS60pn7"},"source":["Choose your optimizer and the loss functions for the classification and bounding box regression."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ecCGMT8k0pn7"},"outputs":[],"source":["cnn = CNN(2)\n","cnn = cnn.to(device)\n","\n","criterion_cls = None\n","criterion_bbox = None\n","optimizer = None\n","#############################################################################\n","#                           START OF YOUR CODE                              #\n","#############################################################################\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","#############################################################################\n","#                             END OF YOUR CODE                              #\n","#############################################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x1MDquw20pn7","scrolled":false},"outputs":[],"source":["best_model,history = train_model(cnn, criterion_cls, criterion_bbox, optimizer, num_epochs=10)"]},{"cell_type":"markdown","metadata":{"id":"-k8iH1730pn7"},"source":["Once you are pleased with your results, see how your model can predict and localize cats and dogs!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74CWGgYX0pn7"},"outputs":[],"source":["# Get a batch of validation data\n","sample = next(iter(dataloaders['val']))\n","with torch.no_grad():\n","    images = sample['image']\n","    images = images.to(device)\n","    label_pred, bbox_pred = best_model(images)\n","    _, label_pred = torch.max(label_pred, 1)\n","imshow(sample['image'], label_pred.cpu(), bbox_pred.cpu())"]},{"cell_type":"markdown","metadata":{"id":"L1hbfE5t0pn7"},"source":["## visualizations\n","\n","Your visualizations here:\n","- IoU / Accuracy / Loss on training and validation datasets as a function of the epoch).\n","- Only visualize the results of your best model.\n","\n","**(10 Points)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n9H-fq4j0pn7"},"outputs":[],"source":["def plot_metrics(history):\n","    \"\"\"\n","    Visualize IoU, Accuracy, and Loss over epochs.\n","\n","    Args:\n","        history: Dictionary containing training and validation metrics.\n","    \"\"\"\n","#############################################################################\n","#                           START OF YOUR CODE                              #\n","#############################################################################\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","#############################################################################\n","#                             END OF YOUR CODE                              #\n","#############################################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sy06YA84H20A"},"outputs":[],"source":["plot_metrics(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iwQJSUNsoY-o"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.8"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}